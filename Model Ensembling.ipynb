{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power of Model Ensembling\n",
    "\n",
    "Ensemble model combines multiple 'individual' (diverse) models together and delivers superior prediction power. ... Basically, an ensemble is a supervised learning technique for combining multiple weak learners/ models to produce a strong learner. Ensemble model works better, when we ensemble models with low correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import (AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, GradientBoostingRegressor)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics, linear_model, naive_bayes\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from scipy import sparse\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DATA préalablement nettoyée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Chargement du fichier DataClean.csv dans le dataframe df\n",
    "df = pd.read_csv(\"DataClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selection des 20 premier variables : Random Forest Result\n",
    "SelectedFeatures=['var38',\n",
    " 'ind_var30',\n",
    " 'var15',\n",
    " 'saldo_medio_var5_ult1',\n",
    " 'saldo_var30',\n",
    " 'saldo_medio_var5_ult3',\n",
    " 'num_meses_var5_ult3',\n",
    " 'num_var30',\n",
    " 'num_var35',\n",
    " 'imp_op_var41_efect_ult1',\n",
    " 'var36',\n",
    " 'num_var22_ult3',\n",
    " 'num_var22_ult1',\n",
    " 'imp_op_var41_efect_ult3',\n",
    " 'num_var45_hace3',\n",
    " 'saldo_var5',\n",
    " 'num_var22_hace2',\n",
    " 'imp_op_var41_ult1',\n",
    " 'num_med_var45_ult3',\n",
    " 'num_var4',\n",
    " 'TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.copy()[SelectedFeatures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var38</th>\n",
       "      <th>ind_var30</th>\n",
       "      <th>var15</th>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <th>saldo_var30</th>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <th>num_meses_var5_ult3</th>\n",
       "      <th>num_var30</th>\n",
       "      <th>num_var35</th>\n",
       "      <th>imp_op_var41_efect_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>num_var22_ult3</th>\n",
       "      <th>num_var22_ult1</th>\n",
       "      <th>imp_op_var41_efect_ult3</th>\n",
       "      <th>num_var45_hace3</th>\n",
       "      <th>saldo_var5</th>\n",
       "      <th>num_var22_hace2</th>\n",
       "      <th>imp_op_var41_ult1</th>\n",
       "      <th>num_med_var45_ult3</th>\n",
       "      <th>num_var4</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49278.030000</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67333.770000</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64007.970000</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>91.56</td>\n",
       "      <td>70.62</td>\n",
       "      <td>138.84</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>70.62</td>\n",
       "      <td>3</td>\n",
       "      <td>195.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117310.979016</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>40501.08</td>\n",
       "      <td>135003.00</td>\n",
       "      <td>13501.47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           var38  ind_var30  var15  saldo_medio_var5_ult1  saldo_var30  \\\n",
       "0   39205.170000          0     23                   0.00         0.00   \n",
       "1   49278.030000          1     34                   0.00       300.00   \n",
       "2   67333.770000          1     23                   3.00         3.00   \n",
       "3   64007.970000          1     37                  91.56        70.62   \n",
       "4  117310.979016          1     39               40501.08    135003.00   \n",
       "\n",
       "   saldo_medio_var5_ult3  num_meses_var5_ult3  num_var30  num_var35  \\\n",
       "0                   0.00                    0          0          0   \n",
       "1                   0.00                    1          3          3   \n",
       "2                   2.07                    3          3          3   \n",
       "3                 138.84                    2          3          9   \n",
       "4               13501.47                    3          3          3   \n",
       "\n",
       "   imp_op_var41_efect_ult1   ...    num_var22_ult3  num_var22_ult1  \\\n",
       "0                      0.0   ...                 0               0   \n",
       "1                      0.0   ...                 0               0   \n",
       "2                      0.0   ...                 0               0   \n",
       "3                      0.0   ...                 3               0   \n",
       "4                      0.0   ...                 9               6   \n",
       "\n",
       "   imp_op_var41_efect_ult3  num_var45_hace3  saldo_var5  num_var22_hace2  \\\n",
       "0                      0.0                0        0.00                0   \n",
       "1                      0.0                0        0.00                0   \n",
       "2                      0.0                0        3.00                0   \n",
       "3                      0.0                3       70.62                3   \n",
       "4                      0.0                0        0.00                3   \n",
       "\n",
       "   imp_op_var41_ult1  num_med_var45_ult3  num_var4  TARGET  \n",
       "0                0.0                   0         0       0  \n",
       "1                0.0                   0         1       0  \n",
       "2                0.0                   0         1       0  \n",
       "3              195.0                  15         3       0  \n",
       "4                0.0                   0         1       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echantillonnage de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y, X, X_train, X_test, Y_train, Y_test = \"\"\n",
    "\n",
    "def splitData(df):\n",
    "    Y = df.TARGET\n",
    "    X = df.drop(['TARGET'], axis=1)\n",
    "\n",
    "    # diviser X et Y en training and testing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    return  train_test_split(X, Y, test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = splitData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.to_csv(\"X_train.csv\")\n",
    "X_test.to_csv(\"X_test.csv\")\n",
    "Y_train.to_csv(\"Y_train.csv\")\n",
    "Y_test.to_csv(\"Y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "poids = []\n",
    "O = 0.5/sum(Y_train==1)\n",
    "Z = 0.5/sum(Y_train==0)\n",
    "for i in Y_train:\n",
    "    if i==0:\n",
    "        poids.append(Z)\n",
    "    else :\n",
    "        poids.append(O)\n",
    "\n",
    "poids = np.array(poids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Base Estimators :</h5>\n",
    "<ul> \n",
    "    <li><h9>DecisionTreeClassifier x100</h9></li>\n",
    "    <li><h9>RandomForestClassifier x100</h9></li>\n",
    "    <li><h9>LogisticRegression x100</h9></li>\n",
    "    <li><h9>BernoulliNB x100</h9></li>\n",
    "    <li><h9>KNeighborsClassifier x100</h9></li>\n",
    "    <li><h9>ExtraTreesClassifier x100</h9></li>\n",
    "    <li><h9>SVC x1</h9></li>\n",
    "    <li><h9>LinearSVC x100</h9></li>\n",
    "    <li><h9>GradientBoostingClassifier x100</h9></li>\n",
    "    <li><h9>SGDClassifier x100</h9></li>\n",
    "    <li><h9>MLPClassifier x100</h9></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RandomPredictSearch(header, clf, param_dic, n_iteration, metric='roc_auc', Xt=X_train, Yt=Y_train, Xv=X_test, n_iter_search=3):\n",
    "    pred_df=pd.DataFrame()\n",
    "    params=[]\n",
    "    for t in xrange(n_iteration):\n",
    "        # run randomized search\n",
    "        random_search = RandomizedSearchCV(clf, param_distributions=param_dic, n_iter=n_iter_search, scoring=metric, n_jobs=-1)\n",
    "        random_search.fit(Xt, Yt)\n",
    "        #Prediction de X_test:\n",
    "        pred_df[header+`t`]=random_search.predict_proba(Xv)[:,1]\n",
    "        #Sauvegarder les parametres utiliser:\n",
    "        params.append(random_search.best_params_)\n",
    "    \n",
    "    # enregistrement ...\n",
    "    pred_df.to_csv(\"BaseEstimators/\"+header+\".csv\")\n",
    "    DumpObject('BaseEstimators/Object_Parametre.'+header, params)\n",
    "    \n",
    "    return pred_df, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RandomizedSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getParamRandom(param_list, param_names):\n",
    "    dictionnaire = {}\n",
    "    for i in xrange(len(param_names)):\n",
    "      dictionnaire[param_names[i]]  = sample(param_list[i],  1)[0] \n",
    "    return dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def DumpObject(name, Object):\n",
    "    # enregistrement ...\n",
    "    with open(name, 'wb') as fichier:\n",
    "        mon_pickler = pickle.Pickler(fichier)\n",
    "        mon_pickler.dump(Object)\n",
    "\n",
    "def LoadObject(name):\n",
    "    # Lecture des objets contenus dans le fichier...\n",
    "    with open(name, 'rb') as fichier:\n",
    "        mon_depickler = pickle.Unpickler(fichier)\n",
    "        object_recupere = mon_depickler.load()\n",
    "    return object_recupere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def perdictProb(header, clf, param_list, param_names, n_iter_search, X, Y, Xv, metric='roc_auc'):\n",
    "    pred_df=pd.DataFrame()\n",
    "    df_header=[]\n",
    "    \n",
    "    for t in xrange(n_iter_search):\n",
    "        newdict = getParamRandom(param_list,param_names)\n",
    "        for p in newdict.keys():\n",
    "            clf.__setattr__(p, newdict[p])\n",
    "        clf.fit(X,Y)\n",
    "        #####\n",
    "        df_header.append(clf.get_params())\n",
    "        #####\n",
    "        pred_df[header+`t`]=clf.predict_proba(Xv)[:,1]\n",
    "    \n",
    "    # enregistrement ...\n",
    "    pred_df.to_csv(header+\".csv\")\n",
    "    DumpObject('Object_Parametre.'+header, df_header)\n",
    "    \n",
    "    return pred_df, df_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14, None],\n",
    "              \"max_features\": sp_randint(1, 20),\n",
    "              \"min_samples_split\": sp_randint(2, 20),\n",
    "              \"min_samples_leaf\": sp_randint(1, 20),\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"n_estimators\" : range(50,999,69),\n",
    "              \"random_state\" : range(1,100,7)}\n",
    "\n",
    "clf_DTC = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presort',\n",
       " 'splitter',\n",
       " 'max_leaf_nodes',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'criterion',\n",
       " 'random_state',\n",
       " 'min_impurity_split',\n",
       " 'max_features',\n",
       " 'max_depth',\n",
       " 'class_weight']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_DTC.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x1007ce2b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/salah...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x1007ce2b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/salah...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    584         \n    585         If a global instance already exists, this reinitializes and starts it\n    586         \"\"\"\n    587         app = cls.instance(**kwargs)\n    588         app.initialize(argv)\n--> 589         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    590 \n    591 #-----------------------------------------------------------------------------\n    592 # utility functions, for convenience\n    593 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-12-08T01:12:10.307067', u'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', u'msg_type': u'execute_request', u'session': u'4EE6CE8B40A94ED1B27B47A6F2D194EB', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['4EE6CE8B40A94ED1B27B47A6F2D194EB']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-12-08T01:12:10.307067', u'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', u'msg_type': u'execute_request', u'session': u'4EE6CE8B40A94ED1B27B47A6F2D194EB', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['4EE6CE8B40A94ED1B27B47A6F2D194EB'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-12-08T01:12:10.307067', u'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', u'msg_type': u'execute_request', u'session': u'4EE6CE8B40A94ED1B27B47A6F2D194EB', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)'\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-24-36cd85048802>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n   2830                 code = compiler(mod, cell_name, \"single\")\n-> 2831                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x113e206b0, file \"<ipython-input-24-36cd85048802>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2832                     return True\n   2833 \n   2834             # Flush softspace\n   2835             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x113e206b0, file \"<ipython-input-24-36cd85048802>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x113e206b0, file \"<ipython-input-24-36cd85048802>\", line 1>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/Users/salaheddine/Desktop/S3/Etude_de_cas/Projet2_Santander_Customer_Satisfaction/<ipython-input-24-36cd85048802> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 get_ipython().magic(u'time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)')\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, arg_s=u'time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)')\n   2158         compound statements.\n   2159         \"\"\"\n   2160         # TODO: should we issue a loud deprecation warning here?\n   2161         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2162         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2163         return self.run_line_magic(magic_name, magic_arg_s)\n        self.run_line_magic = <bound method ZMQInteractiveShell.run_line_magic of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        magic_name = u'time'\n        magic_arg_s = u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)'\n   2164 \n   2165     #-------------------------------------------------------------------------\n   2166     # Things related to macros\n   2167     #-------------------------------------------------------------------------\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_line_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name=u'time', line=u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)')\n   2079             kwargs = {}\n   2080             # Grab local namespace if we need it:\n   2081             if getattr(fn, \"needs_local_scope\", False):\n   2082                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2083             with self.builtin_trap:\n-> 2084                 result = fn(*args,**kwargs)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        args = [u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)']\n        kwargs = {'local_ns': {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}}\n   2085             return result\n   2086 \n   2087     def run_cell_magic(self, magic_name, line, cell):\n   2088         \"\"\"Execute the given cell magic.\n\n...........................................................................\n/Users/salaheddine/Desktop/S3/Etude_de_cas/Projet2_Santander_Customer_Satisfaction/<decorator-gen-60> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line=u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', cell=None, local_ns={'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...})\n      1 \n----> 2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/magic.py in <lambda>(f=<function time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', None, {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}), **k={})\n    188     validate_type(magic_kind)\n    189 \n    190     # This is a closure to capture the magic_kind.  We could also use a class,\n    191     # but it's overkill for just that one bit of state.\n    192     def magic_deco(arg):\n--> 193         call = lambda f, *a, **k: f(*a, **k)\n        f = <function time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', None, {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...})\n        k = {}\n    194 \n    195         if callable(arg):\n    196             # \"Naked\" decorator call (just @foo, no args)\n    197             func = arg\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line=u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', cell=None, local_ns={'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...})\n   1172             st = clock2()\n   1173             out = eval(code, glob, local_ns)\n   1174             end = clock2()\n   1175         else:\n   1176             st = clock2()\n-> 1177             exec(code, glob, local_ns)\n        code = <code object <module> at 0x113e20230, file \"<timed exec>\", line 1>\n        glob = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}\n        local_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}\n   1178             end = clock2()\n   1179             out = None\n   1180         wall_end = wtime()\n   1181         # Compute actual times and report\n\n...........................................................................\n/Users/salaheddine/Desktop/S3/Etude_de_cas/Projet2_Santander_Customer_Satisfaction/<timed exec> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/salaheddine/Desktop/S3/Etude_de_cas/Projet2_Santander_Customer_Satisfaction/<ipython-input-15-b025348c3c6d> in RandomPredictSearch(header='DTC', clf=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), param_dic={'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, None], 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': [50, 119, 188, 257, 326, 395, 464, 533, 602, 671, 740, 809, 878, 947], 'random_state': [1, 8, 15, 22, 29, 36, 43, 50, 57, 64, 71, 78, 85, 92, 99]}, n_iteration=1, metric='roc_auc', Xt=               var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], Yt=62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, Xv=               var38  ind_var30  var15  saldo_me...         9         1  \n\n[19005 rows x 20 columns], n_iter_search=3)\n      2     pred_df=pd.DataFrame()\n      3     params=[]\n      4     for t in xrange(n_iteration):\n      5         # run randomized search\n      6         random_search = RandomizedSearchCV(clf, param_distributions=param_dic, n_iter=n_iter_search, scoring=metric, n_jobs=-1)\n----> 7         random_search.fit(Xt, Yt)\n      8         #Prediction de X_test:\n      9         pred_df[header+`t`]=random_search.predict_proba(Xv)[:,1]\n     10         #Sauvegarder les parametres utiliser:\n     11         params.append(random_search.best_params_)\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=None, error_score='raise',...n_train_score=True, scoring='roc_auc', verbose=0), X=               var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], y=62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, groups=None)\n   1185             train/test set.\n   1186         \"\"\"\n   1187         sampled_params = ParameterSampler(self.param_distributions,\n   1188                                           self.n_iter,\n   1189                                           random_state=self.random_state)\n-> 1190         return self._fit(X, y, groups, sampled_params)\n        self._fit = <bound method RandomizedSearchCV._fit of Randomi..._train_score=True, scoring='roc_auc', verbose=0)>\n        X =                var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns]\n        y = 62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64\n        groups = None\n        sampled_params = <sklearn.model_selection._search.ParameterSampler object>\n   1191 \n   1192 \n   1193 \n   1194 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=None, error_score='raise',...n_train_score=True, scoring='roc_auc', verbose=0), X=               var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], y=62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Dec  8 01:12:10 2016\nPID: 27640            Python 2.7.12: /Users/salaheddine/anaconda/bin/python\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'),                var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], 62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([18983, 18984, 18985, ..., 57012, 57013, 57014]), array([    0,     1,     2, ..., 19415, 19490, 19495]), 0, {'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'),                var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], 62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([18983, 18984, 18985, ..., 57012, 57013, 57014]), array([    0,     1,     2, ..., 19415, 19490, 19495]), 0, {'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), X=               var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], y=62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([18983, 18984, 18985, ..., 57012, 57013, 57014]), test=array([    0,     1,     2, ..., 19415, 19490, 19495]), verbose=0, parameters={'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method DecisionTreeClassifier.set_params ...esort=False, random_state=None, splitter='best')>\n        parameters = {'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/base.py in set_params(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), **params={'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'n_estimators'\n        self.__class__.__name__ = 'DecisionTreeClassifier'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter n_estimators for estimator DecisionTreeClassifier. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-36cd85048802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b025348c3c6d>\u001b[0m in \u001b[0;36mRandomPredictSearch\u001b[0;34m(header, clf, param_dic, n_iteration, metric, Xt, Yt, Xv, n_iter_search)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# run randomized search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#Prediction de X_test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpred_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x1007ce2b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/salah...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x1007ce2b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/salah...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    584         \n    585         If a global instance already exists, this reinitializes and starts it\n    586         \"\"\"\n    587         app = cls.instance(**kwargs)\n    588         app.initialize(argv)\n--> 589         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    590 \n    591 #-----------------------------------------------------------------------------\n    592 # utility functions, for convenience\n    593 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-12-08T01:12:10.307067', u'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', u'msg_type': u'execute_request', u'session': u'4EE6CE8B40A94ED1B27B47A6F2D194EB', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['4EE6CE8B40A94ED1B27B47A6F2D194EB']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-12-08T01:12:10.307067', u'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', u'msg_type': u'execute_request', u'session': u'4EE6CE8B40A94ED1B27B47A6F2D194EB', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['4EE6CE8B40A94ED1B27B47A6F2D194EB'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-12-08T01:12:10.307067', u'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', u'msg_type': u'execute_request', u'session': u'4EE6CE8B40A94ED1B27B47A6F2D194EB', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'5A656E114FF1475AA51BDCF0C4C73161', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)'\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-24-36cd85048802>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n   2830                 code = compiler(mod, cell_name, \"single\")\n-> 2831                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x113e206b0, file \"<ipython-input-24-36cd85048802>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2832                     return True\n   2833 \n   2834             # Flush softspace\n   2835             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x113e206b0, file \"<ipython-input-24-36cd85048802>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x113e206b0, file \"<ipython-input-24-36cd85048802>\", line 1>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/Users/salaheddine/Desktop/S3/Etude_de_cas/Projet2_Santander_Customer_Satisfaction/<ipython-input-24-36cd85048802> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 get_ipython().magic(u'time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)')\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, arg_s=u'time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)')\n   2158         compound statements.\n   2159         \"\"\"\n   2160         # TODO: should we issue a loud deprecation warning here?\n   2161         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2162         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2163         return self.run_line_magic(magic_name, magic_arg_s)\n        self.run_line_magic = <bound method ZMQInteractiveShell.run_line_magic of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        magic_name = u'time'\n        magic_arg_s = u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)'\n   2164 \n   2165     #-------------------------------------------------------------------------\n   2166     # Things related to macros\n   2167     #-------------------------------------------------------------------------\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_line_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name=u'time', line=u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)')\n   2079             kwargs = {}\n   2080             # Grab local namespace if we need it:\n   2081             if getattr(fn, \"needs_local_scope\", False):\n   2082                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2083             with self.builtin_trap:\n-> 2084                 result = fn(*args,**kwargs)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        args = [u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)']\n        kwargs = {'local_ns': {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}}\n   2085             return result\n   2086 \n   2087     def run_cell_magic(self, magic_name, line, cell):\n   2088         \"\"\"Execute the given cell magic.\n\n...........................................................................\n/Users/salaheddine/Desktop/S3/Etude_de_cas/Projet2_Santander_Customer_Satisfaction/<decorator-gen-60> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line=u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', cell=None, local_ns={'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...})\n      1 \n----> 2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/magic.py in <lambda>(f=<function time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', None, {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}), **k={})\n    188     validate_type(magic_kind)\n    189 \n    190     # This is a closure to capture the magic_kind.  We could also use a class,\n    191     # but it's overkill for just that one bit of state.\n    192     def magic_deco(arg):\n--> 193         call = lambda f, *a, **k: f(*a, **k)\n        f = <function time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', None, {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...})\n        k = {}\n    194 \n    195         if callable(arg):\n    196             # \"Naked\" decorator call (just @foo, no args)\n    197             func = arg\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line=u'preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)', cell=None, local_ns={'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...})\n   1172             st = clock2()\n   1173             out = eval(code, glob, local_ns)\n   1174             end = clock2()\n   1175         else:\n   1176             st = clock2()\n-> 1177             exec(code, glob, local_ns)\n        code = <code object <module> at 0x113e20230, file \"<timed exec>\", line 1>\n        glob = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}\n        local_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'DumpObject': <function DumpObject>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import numpy as np\\nimport pandas as pd\\nfrom ...port randint as sp_randint\\nfrom random import *\", u'#Chargement du fichier DataClean.csv dans le dataframe df\\ndf = pd.read_csv(\"DataClean.csv\")', u\"#Selection des 20 premier variables : Random F... 'num_med_var45_ult3',\\n 'num_var4',\\n 'TARGET']\", u'df=df.copy()[SelectedFeatures]', u'df.head()', u'#Y, X, X_train, X_test, Y_train, Y_test = \"\"\\n..._test_split(X, Y, test_size=0.25,random_state=1)', u'X_train, X_test, Y_train, Y_test = splitData(df)', u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'def getParamRandom(param_list, param_names):\\n...(param_list[i],  1)[0] \\n    return dictionnaire', u\"import pickle\\n\\ndef DumpObject(name, Object):...mon_depickler.load()\\n    return object_recupere\", u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_DTC = perdictProb(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u\"get_ipython().magic(u'pinfo RandomizedSearchCV')\", u'def RandomPredictSearch(header, clf, param_dic...eader, params)\\n    \\n    return pred_df, params', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', u'params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,...(1,100,7)}\\n\\nclf_DTC = DecisionTreeClassifier()', u'get_ipython().magic(u\\'time preds_DTC, params_...mPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)\\')', ...], 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, ...}\n   1178             end = clock2()\n   1179             out = None\n   1180         wall_end = wtime()\n   1181         # Compute actual times and report\n\n...........................................................................\n/Users/salaheddine/Desktop/S3/Etude_de_cas/Projet2_Santander_Customer_Satisfaction/<timed exec> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/salaheddine/Desktop/S3/Etude_de_cas/Projet2_Santander_Customer_Satisfaction/<ipython-input-15-b025348c3c6d> in RandomPredictSearch(header='DTC', clf=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), param_dic={'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, None], 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': [50, 119, 188, 257, 326, 395, 464, 533, 602, 671, 740, 809, 878, 947], 'random_state': [1, 8, 15, 22, 29, 36, 43, 50, 57, 64, 71, 78, 85, 92, 99]}, n_iteration=1, metric='roc_auc', Xt=               var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], Yt=62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, Xv=               var38  ind_var30  var15  saldo_me...         9         1  \n\n[19005 rows x 20 columns], n_iter_search=3)\n      2     pred_df=pd.DataFrame()\n      3     params=[]\n      4     for t in xrange(n_iteration):\n      5         # run randomized search\n      6         random_search = RandomizedSearchCV(clf, param_distributions=param_dic, n_iter=n_iter_search, scoring=metric, n_jobs=-1)\n----> 7         random_search.fit(Xt, Yt)\n      8         #Prediction de X_test:\n      9         pred_df[header+`t`]=random_search.predict_proba(Xv)[:,1]\n     10         #Sauvegarder les parametres utiliser:\n     11         params.append(random_search.best_params_)\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=None, error_score='raise',...n_train_score=True, scoring='roc_auc', verbose=0), X=               var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], y=62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, groups=None)\n   1185             train/test set.\n   1186         \"\"\"\n   1187         sampled_params = ParameterSampler(self.param_distributions,\n   1188                                           self.n_iter,\n   1189                                           random_state=self.random_state)\n-> 1190         return self._fit(X, y, groups, sampled_params)\n        self._fit = <bound method RandomizedSearchCV._fit of Randomi..._train_score=True, scoring='roc_auc', verbose=0)>\n        X =                var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns]\n        y = 62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64\n        groups = None\n        sampled_params = <sklearn.model_selection._search.ParameterSampler object>\n   1191 \n   1192 \n   1193 \n   1194 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=None, error_score='raise',...n_train_score=True, scoring='roc_auc', verbose=0), X=               var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], y=62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Dec  8 01:12:10 2016\nPID: 27640            Python 2.7.12: /Users/salaheddine/anaconda/bin/python\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'),                var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], 62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([18983, 18984, 18985, ..., 57012, 57013, 57014]), array([    0,     1,     2, ..., 19415, 19490, 19495]), 0, {'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'),                var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], 62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([18983, 18984, 18985, ..., 57012, 57013, 57014]), array([    0,     1,     2, ..., 19415, 19490, 19495]), 0, {'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), X=               var38  ind_var30  var15  saldo_me...         6         2  \n\n[57015 rows x 20 columns], y=62211    0\n18312    0\n71044    0\n38794    0\n2029...\n50057    0\n5192     0\nName: TARGET, dtype: int64, scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([18983, 18984, 18985, ..., 57012, 57013, 57014]), test=array([    0,     1,     2, ..., 19415, 19490, 19495]), verbose=0, parameters={'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method DecisionTreeClassifier.set_params ...esort=False, random_state=None, splitter='best')>\n        parameters = {'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/base.py in set_params(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), **params={'criterion': 'entropy', 'max_depth': 13, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 13, 'n_estimators': 395, 'random_state': 36})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'n_estimators'\n        self.__class__.__name__ = 'DecisionTreeClassifier'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter n_estimators for estimator DecisionTreeClassifier. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%time preds_DTC, params_DTC = RandomPredictSearch(\"DTC\", clf_DTC, params_DTC, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_DTC = {\"max_depth\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14, None],\n",
    "              \"max_features\": sp_randint(1, 20),\n",
    "              \"min_samples_split\": sp_randint(2, 20),\n",
    "              \"min_samples_leaf\": sp_randint(1, 20),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"n_estimators\" : range(50,999,69),\n",
    "              \"random_state\" : range(1,100,7)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier  x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_depth_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14, None]\n",
    "max_features_list = range(1,21)\n",
    "min_samples_split_list = range(2,21)\n",
    "min_samples_leaf_list = range(1,21)\n",
    "bootstrap_list = [True, False]\n",
    "criterion_list = [\"gini\", \"entropy\"]\n",
    "######\n",
    "param_list_RFC = [max_depth_list, max_features_list, min_samples_split_list, min_samples_leaf_list, bootstrap_list, criterion_list]\n",
    "param_names_RFC = ['max_depth', 'max_features', 'min_samples_split', 'min_samples_leaf', 'bootstrap', 'criterion' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_RFC = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 13s, sys: 26.4 s, total: 40min 40s\n",
      "Wall time: 12min 40s\n"
     ]
    }
   ],
   "source": [
    "%time preds_RFC, params_RFC = perdictProb(\"RFC\", clf_RFC, param_list_RFC, param_names_RFC, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_LR = linear_model.LogisticRegression(n_jobs=-1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dual_list =[False, True]\n",
    "tol_list =[0.00004,0.00002,0.00001,0.0001,0.0002,0.0004,0.0009,0.001,0.0014,0.002,0.01]\n",
    "C_list =[0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8]\n",
    "fit_intercept_list =[False, True]\n",
    "class_weight_list =[None, 'balanced']\n",
    "#solver_list =['liblinear','newton-cg', 'lbfgs', 'sag']\n",
    "max_iter_list =[50,90,100,120,160,200]\n",
    "#multi_class_list =['ovr', 'multinomial']\n",
    "warm_start_list =[False, True]\n",
    "intercept_scaling_list=[0.9, 1.0, 1.11, 1.6, 2.0, 2.11]\n",
    "\n",
    "######\n",
    "param_list_LR = [tol_list, C_list, fit_intercept_list, class_weight_list, \n",
    "               max_iter_list, warm_start_list, intercept_scaling_list]\n",
    "param_names_LR = [\"tol\", \"C\", \"fit_intercept\", \"class_weight\", \n",
    "                \"max_iter\", \"warm_start\", \"intercept_scaling\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 31s, sys: 1.91 s, total: 3min 33s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%time preds_LR, params_LR = perdictProb(\"LR\", clf_LR, param_list_LR, param_names_LR, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-05,   2.00000000e-05,   3.00000000e-05,\n",
       "         4.00000000e-05,   5.00000000e-05,   6.00000000e-05,\n",
       "         7.00000000e-05,   8.00000000e-05,   9.00000000e-05])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.00001,0.0001,0.00001,dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_list=[0.061, 0.05, 0.041, 0.04, 0.032, 0.02, 0.021, 1.0, 1.3, 1.6, 1.4, 1.8, 1.9, 2.0]\n",
    "binarize_list=[2.0, 1.9, 0.6, 1.4, 1.2, 1.0, 0.5, 0.7, 0.0]\n",
    "fit_prior_list=[False, True]\n",
    "\n",
    "######\n",
    "param_list_NB = [alpha_list, binarize_list, fit_prior_list]\n",
    "param_names_NB = [\"alpha\", \"binarize\", \"fit_prior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_NB = naive_bayes.BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 1.17 s, total: 15.3 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%time preds_NB, params_NB = perdictProb(\"NB\", clf_NB, param_list_NB, param_names_NB, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#roc_auc_score(Y_test, preds_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors_list=range(3,9)\n",
    "weights_list=['uniform', 'distance']\n",
    "#algorithm_list=['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "leaf_size_list=[20,30,40]\n",
    "\n",
    "######\n",
    "param_list_KNC = [n_neighbors_list, weights_list, leaf_size_list]\n",
    "param_names_KNC = [\"n_neighbors\", \"weights\", \"leaf_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_header=[]\n",
    "def perdictProbPerIter(header, clf, param_list, param_names, n_iter_search, X, Y, Xv, metric='roc_auc'):\n",
    "    for t in xrange(n_iter_search):\n",
    "        newdict = getParamRandom(param_list,param_names)\n",
    "        for p in newdict.keys():\n",
    "            clf.__setattr__(p, newdict[p])\n",
    "        clf.fit(X,Y)\n",
    "        #####\n",
    "        df_header.append(clf.get_params())\n",
    "        #####\n",
    "        # enregistrement de l'iteration t...\n",
    "        DumpObject(\"PerdictProbPerIter/df.\"+header+`t`, clf.predict_proba(Xv)[:,1])\n",
    "    \n",
    "    \n",
    "     # enregistrement\n",
    "    #DumpObject('Object_Parametre.'+header, df_header)\n",
    "    \n",
    "    #return df_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_KNC = KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 11s, sys: 1.95 s, total: 4min 13s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%time preds_KNC, params_KNC = perdictProb(\"KNC\", clf_KNC, param_list_KNC, param_names_KNC, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also\n",
    "--------\n",
    "RadiusNeighborsClassifier\n",
    "KNeighborsRegressor\n",
    "RadiusNeighborsRegressor\n",
    "NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreesClassifier x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_depth_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14, None]\n",
    "max_features_list = range(1,21)\n",
    "min_samples_split_list = range(2,21)\n",
    "min_samples_leaf_list = range(1,21)\n",
    "bootstrap_list = [True, False]\n",
    "criterion_list = [\"gini\", \"entropy\"]\n",
    "n_estimators_list =[50, 60, 70, 80, 90, 100]\n",
    "######\n",
    "param_list_XT = [max_depth_list, max_features_list, min_samples_split_list, min_samples_leaf_list, bootstrap_list, criterion_list, n_estimators_list]\n",
    "param_names_XT = ['max_depth', 'max_features', 'min_samples_split', 'min_samples_leaf', 'bootstrap', 'criterion', 'n_estimators' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_XT =ExtraTreesClassifier(n_jobs=-1, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 21s, sys: 17.1 s, total: 8min 38s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%time preds_XT, params_XT = perdictProb(\"XT\", clf_XT, param_list_XT, param_names_XT, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C_list = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0]\n",
    "gamma_list = ['auto', 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "kernel_list=['rbf', 'linear', 'poly', 'sigmoid', 'precomputed']\n",
    "degree_list=range(3,7)\n",
    "coef0_list=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "shrinking_list=[False, True]\n",
    "tol_list=[0.001, 0.0001,0.0002,0.0004,0.0009,0.001,0.0014,0.002,0.01, 0.1]\n",
    "class_weight_list=[None, 'balanced']\n",
    "verbose_list=[False, True]\n",
    "random_state_list =range(0,101,7)\n",
    "######\n",
    "param_list_SVC = [random_state_list, C_list, gamma_list, kernel_list, degree_list, coef0_list, shrinking_list, tol_list, class_weight_list, verbose_list]\n",
    "param_names_SVC = [\"random_state\",\"C\", \"gamma\", \"kernel\", \"degree\", \"coef0\", \"shrinking\", \"tol\", \"class_weight\", \"verbose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_SVC = SVC(probability=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 32min 53s, sys: 41 s, total: 1h 33min 34s\n",
      "Wall time: 1h 39min 56s\n"
     ]
    }
   ],
   "source": [
    "%time preds_SVC, params_SVC = perdictProb(\"SVC\", clf_SVC, param_list_SVC, param_names_SVC, 3, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50600400653257493"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_test, preds_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perdictCalibratedProb(header, clf, param_list, param_names, n_iter_search, X, Y, Xv, metric='roc_auc'):\n",
    "    pred_df=pd.DataFrame()\n",
    "    df_header=[]\n",
    "    \n",
    "    for t in xrange(n_iter_search):\n",
    "        newdict = getParamRandom(param_list,param_names)\n",
    "        for p in newdict.keys():\n",
    "            clf.__setattr__(p, newdict[p])\n",
    "        clf.fit(X,Y)\n",
    "        CCC=CalibratedClassifierCV(base_estimator=clf).fit(X,Y)\n",
    "        #####\n",
    "        df_header.append(clf.get_params())\n",
    "        #####\n",
    "        pred_df[header+`t`]=CCC.predict_proba(Xv)[:,1]\n",
    "    \n",
    "    # enregistrement ...\n",
    "    pred_df.to_csv(header+\".csv\")\n",
    "    DumpObject('Object_Parametre.'+header, df_header)\n",
    "    \n",
    "    return pred_df, df_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_list = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0]\n",
    "tol_list=[0.001, 0.0001,0.0002,0.0004,0.0009,0.001,0.0014,0.002,0.01, 0.1]\n",
    "class_weight_list=[None, 'balanced']\n",
    "max_iter_list=range(1000,2000, 90)\n",
    "random_state_list = range(1,100,7)\n",
    "######\n",
    "param_list_LSVC = [C_list, tol_list, class_weight_list, max_iter_list, random_state_list]\n",
    "param_names_LSVC = [\"C\", \"tol\", \"class_weight\", \"max_iter\", \"random_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_LSVC = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 44min 36s, sys: 43.3 s, total: 1h 45min 19s\n",
      "Wall time: 1h 44min 42s\n"
     ]
    }
   ],
   "source": [
    "%time preds_LSVC, params_LSVC = perdictCalibratedProb(\"LSVC\", clf_LSVC, param_list_LSVC, param_names_LSVC, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5559422852251743"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_test, preds_LSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_depth_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14, None]\n",
    "n_estimators_list =[50, 70, 80, 100, 140, 170]\n",
    "subsample_list = [ 0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]\n",
    "max_features_list = range(1,19)\n",
    "#warm_start_list = [False, True]\n",
    "learning_rate_liste = [ 0.1 ,  0.26,  0.42,  0.58,  0.74,  0.9 ]\n",
    "min_samples_split_list = range(2,21)\n",
    "min_samples_leaf_list = range(1,21)\n",
    "######\n",
    "param_list_GBC = [max_depth_list, max_features_list, n_estimators_list, subsample_list, learning_rate_liste, min_samples_split_list, min_samples_leaf_list]\n",
    "param_names_GBC = ['max_depth', 'max_features', 'n_estimators', 'subsample', 'learning_rate', 'min_samples_split', 'min_samples_leaf' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GBC = GradientBoostingClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 27s, sys: 12.7 s, total: 31min 40s\n",
      "Wall time: 49min 47s\n"
     ]
    }
   ],
   "source": [
    "%time preds_GBC, params_GBC = perdictProb(\"GBC\", clf_GBC, param_list_GBC, param_names_GBC, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "listReplace=[]\n",
    "for i in preds_GBC.columns.values:\n",
    "    if pd.isnull(preds_GBC[i]).sum()!=0:\n",
    "        print i,pd.isnull(preds_GBC[i]).sum()\n",
    "        listReplace.append(i)\n",
    "    \n",
    "print listReplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replacePredictNaN(header, clf, param_list, param_names, pred_df, df_header, listReplace, X, Y, Xv, metric='roc_auc'):\n",
    "    \n",
    "    for t in listReplace:\n",
    "        newdict = getParamRandom(param_list,param_names)\n",
    "        for p in newdict.keys():\n",
    "            clf.__setattr__(p, newdict[p])\n",
    "        clf.fit(X,Y)\n",
    "        #####\n",
    "        df_header[int(t.rsplit(header)[1])] = clf.get_params()\n",
    "        #####\n",
    "        pred_df[t]=clf.predict_proba(Xv)[:,1]\n",
    "    \n",
    "    return pred_df, df_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 1.24 s, total: 1min 17s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%time pred_df_gbc, df_header_gbc = replacePredictNaN(\"GBC\", clf_GBC, param_list_GBC, param_names_GBC, preds_GBC, params_GBC, listReplace, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enregistrement ...\n",
    "pred_df_gbc.to_csv(\"GBC.csv\")\n",
    "DumpObject('Object_Parametre.'+\"GBC\", df_header_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14, None]\n",
    "n_estimators_list =[50, 70, 80, 100, 140, 170]\n",
    "subsample_list = [ 0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]\n",
    "max_features_list = range(1,19)\n",
    "alpha_list=np.arange(0.0,1.1,0.01)\n",
    "learning_rate_liste = [ 0.1 ,  0.26,  0.42,  0.58,  0.74,  0.9 ]\n",
    "min_samples_split_list = range(2,21)\n",
    "min_samples_leaf_list = range(1,21)\n",
    "random_state_list = range(1,100,7)\n",
    "######\n",
    "param_list_GBR = [random_state_list, alpha_list, max_depth_list, max_features_list, n_estimators_list, subsample_list, learning_rate_liste, min_samples_split_list, min_samples_leaf_list]\n",
    "param_names_GBR = ['random_state','alpha', 'max_depth', 'max_features', 'n_estimators', 'subsample', 'learning_rate', 'min_samples_split', 'min_samples_leaf' ]\n",
    "\n",
    "clf_GBR = GradientBoostingRegressor()\n",
    "%time preds_GBR, params_GBR = perdictCalibratedProb(\"GBR\", clf_GBR, param_list_GBR, param_names_GBR, 1, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_sizes_list =[(100, ),(200, ),(300, ),(400, ),(500, ),(600, ),(700, )]\n",
    "activation_list =['identity', 'logistic', 'tanh', 'relu']\n",
    "solver_list =['adam', 'lbfgs', 'sgd']\n",
    "alpha_list =np.arange(0.0001,0.02,0.0003)\n",
    "learning_rate_list =['constant', 'invscaling', 'adaptive']\n",
    "learning_rate_init_list =np.arange(0.001,0.01,0.0003)\n",
    "power_t_list =np.arange(0.4,0.7,0.1)\n",
    "max_iter_list =range(200,500,60)\n",
    "random_state_list =range(0,101,7)\n",
    "tol_list =np.arange(0.00001,0.001,0.00003)\n",
    "momentum_list =np.arange(0.7,1.0,0.1)\n",
    "nesterovs_momentum_list =[True, False]\n",
    "beta_1_list =np.arange(0.8,1.0,0.01)\n",
    "beta_2_list =np.arange(0.9,1.0,0.001)\n",
    "epsilon_list =np.arange(1e-09,1e-07,3e-09)\n",
    "######\n",
    "param_list_MLPC = [hidden_layer_sizes_list, activation_list, solver_list, alpha_list, learning_rate_list,\n",
    "                  learning_rate_init_list, power_t_list, max_iter_list, random_state_list, tol_list, momentum_list,\n",
    "                 nesterovs_momentum_list, beta_1_list, beta_2_list, epsilon_list]\n",
    "param_names_MLPC = ['hidden_layer_sizes', 'activation', 'solver', 'alpha', 'learning_rate',\n",
    " 'learning_rate_init', 'power_t', 'max_iter', 'random_state', 'tol', \n",
    " 'momentum', 'nesterovs_momentum', 'beta_1', 'beta_2', 'epsilon' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_MLPC = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salaheddine/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 4min 13s, sys: 22min 38s, total: 2h 26min 52s\n",
      "Wall time: 4h 33min 26s\n"
     ]
    }
   ],
   "source": [
    "%time preds_MLPC, params_MLPC = perdictProb(\"MLPC\", clf_MLPC, param_list_MLPC, param_names_MLPC, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50071729573568668"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_test, preds_MLPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_MLPC = pd.read_csv(\"MLPC.csv\")\n",
    "params_MLPC = LoadObject(\"Object_Parametre.MLPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "listReplace=[]\n",
    "for i in preds_MLPC.columns.values:\n",
    "    if pd.isnull(preds_MLPC[i]).sum()!=0:\n",
    "        print i,pd.isnull(preds_MLPC[i]).sum()\n",
    "        listReplace.append(i)\n",
    "    \n",
    "print listReplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 16s, sys: 2min 26s, total: 15min 42s\n",
      "Wall time: 9min 11s\n"
     ]
    }
   ],
   "source": [
    "%time pred_df_MLPC, df_header_MLPC = replacePredictNaN(\"MLPC\", clf_MLPC, param_list_MLPC, param_names_MLPC, preds_MLPC, params_MLPC, listReplace, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# enregistrement ...\n",
    "pred_df_MLPC.to_csv(\"MLPC.csv\")\n",
    "DumpObject('Object_Parametre.'+\"MLPC\", df_header_MLPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_list = ['log', 'modified_huber']\n",
    "penalty_list = ['elasticnet']\n",
    "alpha_list = [0.0001, 0.001, 0.01, 0.1]\n",
    "learning_rate_list = ['constant', 'optimal']\n",
    "n_iter_list = [2, 5, 7, 10]\n",
    "eta0_list = [0.001, 0.01, 0.1]\n",
    "class_weight_list=[None, \"balanced\"]\n",
    "\n",
    "######\n",
    "param_list_SGDC = [ penalty_list, alpha_list, learning_rate_list, n_iter_list, eta0_list, loss_list, class_weight_list]\n",
    "param_names_SGDC = [ 'penalty', 'alpha', 'learning_rate', 'n_iter', 'eta0', 'loss', 'class_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_SGDC = SGDClassifier(n_jobs=-1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 900 ms, total: 31.1 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%time preds_SGDC, params_SGDC = perdictProb(\"SGDC\", clf_SGDC, param_list_SGDC, param_names_SGDC, 100, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51412188352489807"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_test, preds_SGDC.SGDC14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Combiner toutes les prédictons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNC\n",
      "LR\n",
      "LSVC\n",
      "NB\n",
      "RFC\n",
      "SVC\n",
      "XT\n",
      "GBC\n",
      "MLPC\n",
      "SGDC\n"
     ]
    }
   ],
   "source": [
    "AllModeles = [\"DTC\",\"KNC\", \"LR\", \"LSVC\", \"NB\", \"RFC\", \"SVC\", \"XT\", \"GBC\", \"MLPC\", \"SGDC\"]\n",
    "AllData = pd.read_csv(\"prediction/DTC.csv\", index_col=0)\n",
    "for m in AllModeles[1:]:\n",
    "    print m\n",
    "    temp = pd.read_csv(\"prediction/\"+m+\".csv\", index_col=0)\n",
    "    temp.columns.values\n",
    "    AllData = pd.DataFrame( data=np.hstack((AllData, temp)) , columns=AllData.columns.values.tolist()+temp.columns.values.tolist() )\n",
    "# enregistrement ...\n",
    "AllData.to_csv(\"prediction/AllPredictionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "OmarPreds = pd.read_csv(\"prediction/FinalPredectionKNeighborsClassifier.csv\")\n",
    "AllData_Sr_Os = pd.DataFrame( data=np.hstack((AllData, OmarPreds)) , columns=AllData.columns.values.tolist()+OmarPreds.columns.values.tolist() )\n",
    "AnouarPreds = pd.read_csv(\"prediction/all_prob_Classifier.csv\")\n",
    "AllData_Sr_Os_Aj = pd.DataFrame( data=np.hstack((AllData_Sr_Os, AnouarPreds)) , columns=AllData_Sr_Os.columns.values.tolist()+AnouarPreds.columns.values.tolist() )\n",
    "#enregistrement ...\n",
    "AllData_Sr_Os_Aj.to_csv(\"prediction/AllData_Sr_Os_Aj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AllData_Sr_Os_Aj=pd.read_csv(\"prediction/AllData_Sr_Os_Aj.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split All Prediction Data to 50% x 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taille = int(len(Y_test)*0.5)\n",
    "HalfPD1=pd.DataFrame()\n",
    "HalfPD2=pd.DataFrame()\n",
    "\n",
    "D1 = AllData_Sr_Os_Aj.head(1+taille) \n",
    "TY1 = pd.DataFrame(Y_test).head(1+taille)\n",
    "\n",
    "HalfPD1 = pd.DataFrame( data=np.hstack((D1, TY1))\n",
    "                       , columns=AllData_Sr_Os_Aj.columns.values.tolist()+TY1.columns.values.tolist() )\n",
    "\n",
    "\n",
    "D2 = AllData_Sr_Os_Aj.tail(taille)\n",
    "TY2 = pd.DataFrame(Y_test).tail(taille)\n",
    "\n",
    "HalfPD2 = pd.DataFrame( data=np.hstack((D2, TY2))\n",
    "                       , columns=AllData_Sr_Os_Aj.columns.values.tolist()+TY2.columns.values.tolist() )\n",
    "\n",
    "HalfPD1.to_csv(\"prediction/HalfPD1.csv\")\n",
    "HalfPD2.to_csv(\"prediction/HalfPD2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19005\n"
     ]
    }
   ],
   "source": [
    "print len(HalfPD2)+ len(HalfPD1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a New Prediction data from last prediction by using this Stackers [\"LR\", \"RFC\", \"XT\", \"GBC\", \"NB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBags(DFpred, Size_Bag):\n",
    "    return sample(DFpred.columns.values, Size_Bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def predBags(df_predict, Size_Bag, Yv=Y_test):\n",
    "    stackers = [\"LR\", \"RFC\", \"XT\", \"GBC\", \"NB\"]\n",
    "    NewPred = pd.DataFrame()\n",
    "    taille = int(len(Yv)*0.5)\n",
    "    for m in stackers:\n",
    "        print m\n",
    "        for t in range(40):\n",
    "            tempDF = df_predict[getBags(df_predict, Size_Bag)]\n",
    "            Half1 = tempDF.head(1+taille)\n",
    "            Half2 = tempDF.tail(taille)\n",
    "            stacker1 = getStacker(m)\n",
    "            stacker2 = clone(stacker1)\n",
    "            stacker1.fit( Half1, Yv.head(1+taille))\n",
    "            stacker2.fit( Half2, Yv.head(taille))\n",
    "            #stacker1.predict_proba(tempDF.tail(taille))[:,1]\n",
    "            #stacker2.predict_proba(tempDF.head(1+taille))[:,1]\n",
    "            NewPred[\"stacker_\"+m+`t`] = np.array(stacker2.predict_proba(Half1)[:,1].tolist() + stacker1.predict_proba(Half2)[:,1].tolist())\n",
    "            \n",
    "    return NewPred\n",
    "\n",
    "def ExtraPredBags(df_predict, Size_Bag, Yv=Y_test, xtra=3):\n",
    "    stackers = [\"LR\", \"RFC\", \"XT\", \"GBC\", \"NB\"]\n",
    "    NewPred = pd.DataFrame()\n",
    "    taille = int(len(Yv)*0.5)\n",
    "    for m in stackers:\n",
    "        print m\n",
    "        for t in range(40):\n",
    "            dataList = np.zeros_like(Yv)\n",
    "            tempDF = df_predict[getBags(df_predict, Size_Bag)]\n",
    "            Half1 = tempDF.head(1+taille)\n",
    "            Half2 = tempDF.tail(taille)\n",
    "            for x in range(xtra):\n",
    "                stacker1 = getStacker(m)\n",
    "                stacker2 = clone(stacker1)\n",
    "                stacker1.fit( Half1, Yv.head(1+taille))\n",
    "                stacker2.fit( Half2, Yv.head(taille))\n",
    "                #stacker1.predict_proba(tempDF.tail(taille))[:,1]\n",
    "                #stacker2.predict_proba(tempDF.head(1+taille))[:,1]\n",
    "                dataList = dataList + np.array(stacker2.predict_proba(Half1)[:,1].tolist() + stacker1.predict_proba(Half2)[:,1].tolist())\n",
    "            NewPred[\"stacker_\"+m+`t`] = dataList/xtra\n",
    "            \n",
    "    return NewPred\n",
    "\n",
    "def BestPredBags(df_predict, Size_Bag, Yv=Y_test, best=3):\n",
    "    stackers = [\"LR\", \"RFC\", \"XT\", \"GBC\", \"NB\"]\n",
    "    NewPred = pd.DataFrame()\n",
    "    taille = int(len(Yv)*0.5)\n",
    "    for m in stackers:\n",
    "        print m\n",
    "        for t in range(40):\n",
    "            bestList = np.array([])\n",
    "            score = 0\n",
    "            tempDF = df_predict[getBags(df_predict, Size_Bag)]\n",
    "            Half1 = tempDF.head(1+taille)\n",
    "            Half2 = tempDF.tail(taille)\n",
    "            for x in range(best):\n",
    "                stacker1 = getStacker(m)\n",
    "                stacker2 = clone(stacker1)\n",
    "                stacker1.fit( Half1, Yv.head(1+taille))\n",
    "                stacker2.fit( Half2, Yv.head(taille))\n",
    "                dataList = np.array(stacker2.predict_proba(Half1)[:,1].tolist() + stacker1.predict_proba(Half2)[:,1].tolist())\n",
    "                if roc_auc_score(Yv, dataList) > score:\n",
    "                    bestList=dataList\n",
    "            \n",
    "            NewPred[\"stacker_\"+m+`t`] = bestList\n",
    "            \n",
    "    return NewPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getStacker(nom):\n",
    "    if nom==\"LR\":\n",
    "        stacker = linear_model.LogisticRegression(n_jobs=-1, random_state=1)\n",
    "        newdict = getParamRandom(param_list_LR,param_names_LR)\n",
    "        for p in newdict.keys():\n",
    "            stacker.__setattr__(p, newdict[p])\n",
    "        return stacker\n",
    "    \n",
    "    elif nom==\"RFC\":\n",
    "        stacker = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "        newdict = getParamRandom(param_list_RFC,param_names_RFC)\n",
    "        for p in newdict.keys():\n",
    "            stacker.__setattr__(p, newdict[p])\n",
    "        return stacker\n",
    "    \n",
    "    elif nom==\"XT\":\n",
    "        stacker = ExtraTreesClassifier(n_jobs=-1, random_state=5)\n",
    "        newdict = getParamRandom(param_list_XT,param_names_XT)\n",
    "        for p in newdict.keys():\n",
    "            stacker.__setattr__(p, newdict[p])\n",
    "        return stacker\n",
    "    \n",
    "    elif nom==\"GBC\":\n",
    "        stacker = GradientBoostingClassifier(random_state=1)\n",
    "        newdict = getParamRandom(param_list_GBC,param_names_GBC)\n",
    "        for p in newdict.keys():\n",
    "            stacker.__setattr__(p, newdict[p])\n",
    "        return stacker\n",
    "    \n",
    "    elif nom==\"NB\":\n",
    "        stacker = naive_bayes.BernoulliNB()\n",
    "        newdict = getParamRandom(param_list_NB,param_names_NB)\n",
    "        for p in newdict.keys():\n",
    "            stacker.__setattr__(p, newdict[p])\n",
    "        return stacker\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "RFC\n",
      "XT\n",
      "GBC\n",
      "NB\n",
      "CPU times: user 16min 44s, sys: 24.3 s, total: 17min 9s\n",
      "Wall time: 9min 50s\n"
     ]
    }
   ],
   "source": [
    "%time NewPred200 = predBags(AllData_Sr_Os_Aj, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NewPred200.to_csv(\"prediction/NewPred200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "RFC\n",
      "XT\n",
      "GBC\n",
      "NB\n",
      "CPU times: user 3h 42s, sys: 3min 11s, total: 3h 3min 53s\n",
      "Wall time: 1h 42min 3s\n"
     ]
    }
   ],
   "source": [
    "%time ExtraPred200 = ExtraPredBags(AllData_Sr_Os_Aj, Size_Bag=200, xtra=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ExtraPred200.to_csv(\"prediction/ExtraPred200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "RFC\n",
      "XT\n",
      "GBC\n",
      "NB\n",
      "CPU times: user 3h 1min 36s, sys: 3min 41s, total: 3h 5min 18s\n",
      "Wall time: 1h 46min 53s\n"
     ]
    }
   ],
   "source": [
    "%time BestPred200 = BestPredBags(AllData_Sr_Os_Aj, Size_Bag=200, best=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BestPred200.to_csv(\"prediction/BestPred200.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NewPred200 : 0.773521991717 : stacker_XT14\n",
    "#### ExtraPred200 : 0.753228160753 : stacker_XT25\n",
    "#### BestPred200 : 0.766892376898 : stacker_NB15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bestScore(DataF):\n",
    "    score = 0\n",
    "    emp = ''\n",
    "    for i in DataF.columns.values:\n",
    "        score_temp = roc_auc_score(Y_test,DataF[i])\n",
    "        if score<score_temp:\n",
    "            score = score_temp\n",
    "            emp = i\n",
    "    print score, emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753228160753 stacker_XT25\n"
     ]
    }
   ],
   "source": [
    "bestScore(ExtraPred200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "od1=pd.read_csv(\"FinalEnsembleCSVExtraThreeLinear.csv\")\n",
    "od1.drop([\"StackExtraTreesClassifier:0\",\"StackExtraTreesClassifier:1\"], axis=1, inplace=True)\n",
    "od2=pd.read_csv(\"FinalEnsembleLogisticRegression.csv\")\n",
    "od3=pd.read_csv(\"GMBLASTCSV.csv\")\n",
    "omar = pd.concat([od1, od2, od3], axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837192198157 ET_probstack32\n"
     ]
    }
   ],
   "source": [
    "od4=pd.read_csv(\"all_prob_Classifier_Stack.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "omar_anouar =pd.concat([omar, od4], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed  .....  0.0 %\n",
      "_______________________\n",
      "Start :  0.778346855857\n",
      "End   :  0.782967155437 \n",
      "=============================\n",
      "Completed  .....  1.0 %\n",
      "_______________________\n",
      "Start :  0.829917435104\n",
      "End   :  0.833893319655 \n",
      "=============================\n",
      "Completed  .....  11.0 %\n",
      "_______________________\n",
      "Start :  0.830899784921\n",
      "End   :  0.839875036715 \n",
      "=============================\n",
      "CPU times: user 4min 14s, sys: 21.5 s, total: 4min 36s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%time Scores_list, selected_col = ForWardSelection(omar_anouar, 500,iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 165, 235, 197, 178, 0, 143, 127, 127, 119, 119, 119, 116, 116, 125]\n"
     ]
    }
   ],
   "source": [
    "print selected_col[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "omar\n",
    "##############\n",
    "Start :  0.837383748306\n",
    "End   :  0.841068989875 \n",
    "[13, 19, 19, 13, 30, 28, 22, 22, 25, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,\n",
    " 7, 7, 7, 7, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 2, 2, 2,\n",
    " 7, 7, 7, 7, 2, 2, 2, 2, 7, 7, 2, 2, 7, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 7,\n",
    " 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2, 2]\n",
    "\n",
    "omar_anouar\n",
    "##############\n",
    "Start :  0.502424859917\n",
    "End   :  0.841547333673 \n",
    "[9, 165, 235, 197, 178, 0, 143, 127, 127, 119, 119, 119, 116, 116, 125]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selection with remplacement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NewPred200=pd.read_csv(\"prediction/NewPred200.csv\", index_col=0)\n",
    "#ExtraPred200=pd.read_csv(\"prediction/ExtraPred200.csv\", index_col=0)\n",
    "#BestPred200=pd.read_csv(\"prediction/BestPred200.csv\", index_col=0)\n",
    "AllPredictionData=pd.read_csv(\"prediction/AllPredictionData.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ForWardSelection(DataF, nb_mod, iter=20):\n",
    "    Scores_top = [[0,0]]\n",
    "    selected_col_list = []\n",
    "    for it in range(iter):\n",
    "        Scores = []\n",
    "        selected = []\n",
    "        comb = 0\n",
    "        for i in range(3):\n",
    "            col = sample(DataF.columns.values, 1)[0]\n",
    "            #col = \"stacker_XT14\"\n",
    "            comb = comb + DataF[col]\n",
    "            selected.append(col)\n",
    "        Scores.append(roc_auc_score(Y_test, comb/len(selected)))\n",
    "\n",
    "        #Scores = [0]\n",
    "        #selected = []\n",
    "        #comb = 0\n",
    "\n",
    "        #print \"Start : \", Scores[len(Scores)-1]  \n",
    "        for nb in range(nb_mod):\n",
    "            col = sample(DataF.columns.values, 1)[0]\n",
    "            if len(selected)==0:\n",
    "                temp = (DataF[col]+comb)\n",
    "            else:\n",
    "                temp = (DataF[col]+comb)/len(selected)\n",
    "\n",
    "            score_temp = roc_auc_score(Y_test, temp)\n",
    "            if Scores[len(Scores)-1]<=score_temp:\n",
    "                Scores.append(score_temp)\n",
    "                selected.append(col)\n",
    "                comb = comb + temp\n",
    "        #print \"End   : \", Scores[len(Scores)-1],\"\\n=============================\"\n",
    "        if Scores[len(Scores)-1]>Scores_top[len(Scores_top)-1][1]:\n",
    "            Scores_top.append([Scores[0], Scores[len(Scores)-1]])\n",
    "            selected_col_list.append(selected)\n",
    "            print \"Completed  ..... \", ((it+0.0)/iter)*100.0, \"%\\n_______________________\"\n",
    "            print \"Start : \", Scores[0]\n",
    "            print \"End   : \", Scores[len(Scores)-1],\"\\n=============================\"\n",
    "        \n",
    "    return Scores_top, selected_col_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempData = pd.DataFrame( data=np.hstack((NewPred200, ExtraPred200, BestPred200)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed  .....  0.0 %\n",
      "_____________________\n",
      "Start :  0.727320095733\n",
      "End   :  0.779578129218 \n",
      "=============================\n",
      "Completed  .....  3.0 %\n",
      "_____________________\n",
      "Start :  0.726372059971\n",
      "End   :  0.782363066756 \n",
      "=============================\n",
      "Completed  .....  11.0 %\n",
      "_____________________\n",
      "Start :  0.731823632207\n",
      "End   :  0.784136839467 \n",
      "=============================\n",
      "Completed  .....  21.0 %\n",
      "_____________________\n",
      "Start :  0.728412499819\n",
      "End   :  0.786090174405 \n",
      "=============================\n",
      "Completed  .....  26.0 %\n",
      "_____________________\n",
      "Start :  0.7607042256\n",
      "End   :  0.789740075429 \n",
      "=============================\n",
      "CPU times: user 15min 57s, sys: 1min 21s, total: 17min 18s\n",
      "Wall time: 16min 28s\n"
     ]
    }
   ],
   "source": [
    "%time Scores_list, selected_col = ForWardSelection(tempData, 2000,iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('RandoFor_prob', 12)\",\n",
       " \"('DT_pr', 230)\",\n",
       " 'RFC3',\n",
       " 'RFClassifier:336',\n",
       " 'SVR:16',\n",
       " \"('RandoFor_prob', 231)\",\n",
       " 'RFClassifier:38',\n",
       " 'GBMClassifier:67',\n",
       " \"('RandoFor_prob', 5)\",\n",
       " 'RFClassifier:6',\n",
       " 'KNC98',\n",
       " \"('RandoFor_prob', 45)\",\n",
       " 'RFC55',\n",
       " 'KNC17',\n",
       " 'LR17',\n",
       " 'GBMClassifier:13',\n",
       " 'RFClassifier:55',\n",
       " 'GBMClassifier:143',\n",
       " 'RFClassifier:8',\n",
       " 'RFClassifier:8',\n",
       " 'GBMClassifier:71',\n",
       " 'GBMClassifier:112']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_col[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AllPredictionData\n",
    "    \n",
    "    ###############\n",
    "    Scores\n",
    "    Start :  0.83540137839853967\n",
    "    End   :  0.83957530197468599\n",
    "    \n",
    "    Selected_col\n",
    "    ['RFC72', 'RFC70', 'LSVC55', 'SGDC68', 'GBC29', 'GBC58', 'DTC51', 'XT53', 'DTC59', 'DTC92', 'DTC92', 'DTC21', 'GBC34', 'GBC34', 'RFC69', 'XT22', 'XT13', 'DTC15', 'RFC55', 'XT53', 'XT53', 'DTC56', 'GBC2', 'DTC37', 'KNC86', 'KNC57', 'KNC29', 'GBC51']\n",
    "    \n",
    "#### AllData_Sr_Os_Aj\n",
    "    \n",
    "    ###############\n",
    "    Scores\n",
    "    Start :  0.830148431752\n",
    "    End   :  0.840173231723\n",
    "    \n",
    "    Selected_col\n",
    "    [\"('RandoFor_prob', 12)\", \"('DT_pr', 230)\", 'RFC3', 'RFClassifier:336', 'SVR:16', \"('RandoFor_prob', 231)\", 'RFClassifier:38', 'GBMClassifier:67', \"('RandoFor_prob', 5)\", 'RFClassifier:6', 'KNC98', \"('RandoFor_prob', 45)\", 'RFC55', 'KNC17', 'LR17', 'GBMClassifier:13', 'RFClassifier:55', 'GBMClassifier:143', 'RFClassifier:8', 'RFClassifier:8', 'GBMClassifier:71', 'GBMClassifier:112']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
